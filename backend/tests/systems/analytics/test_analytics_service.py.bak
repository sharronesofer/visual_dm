"""
Tests for the analytics service to ensure compliance with Development Bible.
"""

import unittest
from unittest.mock import patch, MagicMock, AsyncMock
import tempfile
import os
import json
import asyncio
from datetime import datetime, timedelta
from pathlib import Path

from backend.systems.analytics.services.analytics_service import (
    AnalyticsService,
    AnalyticsEventType,
)
from backend.systems.analytics.schemas import (
    AnalyticsEventBase,
    GameStartEvent,
    MemoryEvent,
)
from backend.systems.events import EventBase, EventType, EventDispatcher, SystemEvent


class TestAnalyticsService(unittest.TestCase):
    """Test analytics service implementation against Development Bible requirements."""

    def setUp(self):
        """Set up test environment with temporary directory."""
        # Create a temp directory for test data
        self.temp_dir = tempfile.TemporaryDirectory()

        # Patch the analytics data path
        self.analytics_data_path_patcher = patch(
            "backend.systems.analytics.services.analytics_service.ANALYTICS_DATA_PATH",
            Path(self.temp_dir.name),
        )
        self.analytics_data_path_patcher.start()

        # Get the singleton instance of analytics service
        # Create a new instance for testing by bypassing singleton
        AnalyticsService._instance = None
        self.analytics = AnalyticsService(storage_path=Path(self.temp_dir.name))

    def tearDown(self):
        """Clean up after tests."""
        # Stop the background task
        if hasattr(self.analytics, "_worker_task") and self.analytics._worker_task:
            if not self.analytics._worker_task.done():
                self.analytics._worker_task.cancel()

        # Reset singleton for next test
        AnalyticsService._instance = None

        # Clean up patchers
        self.analytics_data_path_patcher.stop()

        # Remove temp directory
        self.temp_dir.cleanup()

    def test_singleton_pattern(self):
        """Test that the service follows singleton pattern as per Development Bible."""
        # Get another instance
        second_instance = AnalyticsService.get_instance()

        # Should be the same instance
        self.assertIs(
            self.analytics,
            second_instance,
            "AnalyticsService should follow singleton pattern per Development Bible",
        )

    def test_event_type_constants(self):
        """Test that event types match the canonical types in Development Bible."""
        # Canonical event types specified in Development Bible
        expected_types = [
            "GameStart",
            "GameEnd",
            "MemoryEvent",
            "RumorEvent",
            "MotifEvent",
            "PopulationEvent",
            "POIStateEvent",
            "FactionEvent",
            "QuestEvent",
            "CombatEvent",
            "TimeEvent",
            "StorageEvent",
            "RelationshipEvent",
            "WorldStateEvent",
            "CustomEvent",
        ]

        # Get the actual event types from the class
        actual_types = AnalyticsEventType.get_all()

        # Check that all expected types are present
        for expected_type in expected_types:
            self.assertIn(
                expected_type,
                actual_types,
                f"Expected event type '{expected_type}' not found",
            )

        # Check that there are no unexpected types
        self.assertEqual(
            len(expected_types),
            len(actual_types),
            "Number of event types doesn't match canonical list",
        )

    @patch("backend.systems.analytics.services.analytics_service.asyncio.create_task")
    def test_async_operation(self, mock_create_task):
        """Test that async operation of the service works as expected."""
        # Set up mock for the coroutine
        mock_worker_coro = MagicMock()
        mock_create_task.return_value = MagicMock()
        
        # Patch the _process_event_queue method to return our mock
        with patch.object(
            AnalyticsService, 
            "_process_event_queue",
            return_value=mock_worker_coro
        ) as mock_process_queue:
            # Ensure async components are initialized
            self.analytics._ensure_async_components()
            
            # Verify create_task was called with the coroutine
            mock_create_task.assert_called_once()
            
            # Queue an event
            test_event = {
                "event_type": "test_event",
                "timestamp": datetime.utcnow().isoformat(),
                "metadata": {"test": "data"}
            }
            
            # Mock the async event queue
            mock_queue = MagicMock()
            mock_queue.put = AsyncMock()
            self.analytics._event_queue = mock_queue
            
            # Use the sync log_event method which should queue the event
            self.analytics.log_event("test_event", metadata={"test": "data"})
            
            # No need to assert anything on the queue.put since we can't await it in a sync test

    def test_structured_event_logging(self):
        """Test structured event logging with proper types."""
        # Override _ensure_async_components to prevent creating the task
        with patch.object(
            AnalyticsService, 
            "_ensure_async_components",
            return_value=None
        ):
            # Log a game start event
            self.analytics.log_event(
                event_type=AnalyticsEventType.GAME_START,
                entity_id="test_session",
                metadata={
                    "session_id": "test_session_123",
                    "user_id": "test_user_456",
                    "client_info": {"platform": "test", "version": "1.0"},
                },
            )

            # Test that the service accepted the event
            # Since the service processes events asynchronously, we test the storage directly
            test_event_data = {
                "event_type": AnalyticsEventType.GAME_START,
                "entity_id": "test_session",
                "metadata": {
                    "session_id": "test_session_123",
                    "user_id": "test_user_456",
                    "client_info": {"platform": "test", "version": "1.0"},
                },
                "timestamp": datetime.utcnow().isoformat(),
            }

            # Call the storage method directly to test the storage functionality
            self.analytics._store_event_sync(test_event_data)

            # Check that the file was created with proper structure
            today = datetime.utcnow().strftime("%Y/%m/%d")
            expected_path = Path(self.temp_dir.name) / today / "GameStart.jsonl"

            self.assertTrue(
                expected_path.exists(),
                f"Expected analytics file not created at {expected_path}",
            )

            # Read the file and check its content
            with open(expected_path, "r") as f:
                content = f.readline().strip()  # Read just one line
                event_data = json.loads(content)

            # Verify proper structure
            self.assertEqual(event_data["event_type"], "GameStart")
            self.assertEqual(event_data["entity_id"], "test_session")
            self.assertEqual(event_data["metadata"]["session_id"], "test_session_123")

    @patch("backend.systems.events.EventDispatcher")
    def test_middleware_integration(self, mock_dispatcher):
        """Test proper middleware integration with event system as per Development Bible."""
        # Mock the event dispatcher
        mock_dispatcher_instance = MagicMock()
        mock_dispatcher.return_value = mock_dispatcher_instance

        # Register with the dispatcher
        self.analytics.register_with_dispatcher(mock_dispatcher_instance)

        # Verify middleware was added
        mock_dispatcher_instance.add_middleware.assert_called_once()

    def test_event_transformation(self):
        """Test event transformation from system events to analytics events."""
        # Create a system event
        system_event = SystemEvent(
            event_type="test_event",
            source="test_source",
            system_name="test_system",
            data={"key": "value"},
        )

        # Override _ensure_async_components to prevent creating the task
        with patch.object(
            AnalyticsService, 
            "_ensure_async_components",
            return_value=None
        ):
            # Create a middleware function
            middleware = self.analytics.get_analytics_middleware()

            # Process the event
            transformed_event = middleware(system_event)

            # Verify the event was transformed correctly and original returned
            self.assertIs(
                system_event,
                transformed_event,
                "Middleware should return the original event",
            )

    def test_dataset_generation(self):
        """Test dataset generation from analytics events."""
        # Prepare some test data
        today = datetime.utcnow().strftime("%Y/%m/%d")
        data_dir = Path(self.temp_dir.name) / today
        data_dir.mkdir(parents=True, exist_ok=True)

        # Create test files with events
        with open(data_dir / "GameStart.jsonl", "w") as f:
            f.write(
                json.dumps(
                    {
                        "event_type": "GameStart",
                        "entity_id": "session1",
                        "timestamp": datetime.utcnow().isoformat(),
                        "metadata": {"session_id": "session1", "user_id": "user1"},
                    }
                )
                + "\n"
            )
            f.write(
                json.dumps(
                    {
                        "event_type": "GameStart",
                        "entity_id": "session2",
                        "timestamp": datetime.utcnow().isoformat(),
                        "metadata": {"session_id": "session2", "user_id": "user2"},
                    }
                )
                + "\n"
            )

        with open(data_dir / "MemoryEvent.jsonl", "w") as f:
            f.write(
                json.dumps(
                    {
                        "event_type": "MemoryEvent",
                        "entity_id": "entity1",
                        "timestamp": datetime.utcnow().isoformat(),
                        "metadata": {"memory_id": "memory1", "action": "created"},
                    }
                )
                + "\n"
            )

        # Generate dataset synchronously (this is tested in more detail in test_utils.py)
        dataset = self.analytics.generate_dataset()

        # Verify basic structure
        self.assertEqual(len(dataset), 3)  # Should be 3 events total
        event_types = [event["event_type"] for event in dataset]
        self.assertEqual(event_types.count("GameStart"), 2)
        self.assertEqual(event_types.count("MemoryEvent"), 1)


if __name__ == "__main__":
    unittest.main()
